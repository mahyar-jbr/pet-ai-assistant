# ğŸ¾ Pet AI Assistant

**Pet AI Assistant** is a modern full-stack web application that helps dog owners build personalized pet profiles and discover tailored food recommendations.  
Itâ€™s built with a **React + Vite** frontend and a **FastAPI + MongoDB** backend, powered by custom **web scrapers** that collect real product data from multiple sources.

---

## âœ¨ Features

- ğŸ¶ **Interactive Pet Profile Form** â€“ Age group, breed size, activity level, dietary goals, and dynamic allergy pills  
- ğŸ§  **Intelligent Recommendation Engine** â€“ Advanced scoring algorithm with hard filters (allergies, kibble size, life stage)  
- ğŸ’¾ **Automatic State Management** â€“ React hooks with localStorage fallback and automatic cleanup 
- ğŸ“Š **Rich Food Cards** â€“ Nutrition indicators, ingredient lists, and compatibility badges  
- ğŸ¨ **Modern UI** â€“ Beautiful gradient designs with smooth animations  
- âš¡ **Fast & Responsive** â€“ Vite HMR for instant development feedback  
- ğŸ”„ **RESTful API** â€“ Clean Python FastAPI backend with MongoDB integration  

---

## ğŸ—‚ï¸ Project Structure

```
Pet-AI-Assistant/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ petApi.js             # Axios API configuration for backend calls
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/               # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ AllergyPills.jsx      # Allergy tag input and removal component
â”‚   â”‚   â”‚   â”œâ”€â”€ ComparisonTool.jsx    # (New) Compare food items visually or by data
â”‚   â”‚   â”‚   â””â”€â”€ FoodCard.jsx          # Displays product details, nutrition info, and icons
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ PetForm.jsx           # Pet profile creation form
â”‚   â”‚   â”‚   â””â”€â”€ Recommendations.jsx   # Displays filtered and sorted food recommendations
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â”œâ”€â”€ form.css              # Styling for PetForm (inputs, layout, themes)
â”‚   â”‚   â”‚   â””â”€â”€ recommendation.css    # Styling for Recommendations page (cards, grids)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ foodUtils.js          # Helper functions for filtering and matching products
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Root component (sets up routes and page structure)
â”‚   â”‚   â”œâ”€â”€ App.css                   # Global UI styling (buttons, layout)
â”‚   â”‚   â”œâ”€â”€ index.css                 # General global styling (fonts, resets)
â”‚   â”‚   â”œâ”€â”€ main.jsx                  # React entry point (mounts App)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ (React standard files)
â”‚   â”‚
â”‚   â”œâ”€â”€ index.html                    # Root HTML template used by Vite
â”‚   â”œâ”€â”€ package.json                  # Frontend dependencies and scripts
â”‚   â”œâ”€â”€ package-lock.json             # Exact dependency lock file
â”‚   â”œâ”€â”€ vite.config.js                # Vite build and dev configuration
â”‚   â”œâ”€â”€ eslint.config.js              # ESLint config for React linting
â”‚   â””â”€â”€ .gitignore                    # Node/Vite ignores (node_modules, dist, etc.)
â”‚
â”œâ”€â”€ backend/
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                 # Web scraping scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Makes 'scrapers' a Python package
â”‚   â”‚   â”œâ”€â”€ orijen_scraper.py     # Scraper for Orijen dog food brand
â”‚   â”‚   â”œâ”€â”€ petvalu_scraper.py    # Scraper for PetValu store products
â”‚   â”‚   â””â”€â”€ scraper_pipeline.py   # Orchestrates and manages multiple scrapers
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_normalizer.py    # Cleans and formats scraped data (standardizes names, numbers)
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                     # Holds scraped product data (gitignored)
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py                   # FastAPI main server entry point, defines routes
â”‚   â”œâ”€â”€ import_products.py        # Imports scraped data into MongoDB
â”‚   â”œâ”€â”€ test_scraper.py           # Testing file for verifying scraper output
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies (FastAPI, Motor, BeautifulSoup, etc.)
â”‚   â”œâ”€â”€ .env.example              # Example environment file with MongoDB connection template
â”‚   â””â”€â”€ .gitignore                # Backend-specific ignores (venv, data files, etc.)
â”‚
â”‚
â””â”€â”€ README.md                 â† This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** (v18+) and npm
- **Python** (3.9+)
- **MongoDB** (local or Atlas)

### 1. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file (copy from .env.example and fill in your MongoDB URL)
cp .env.example .env

# Import sample products
python import_products.py

# Start backend server (runs on http://localhost:8000)
uvicorn main:app --reload --port 8000
```

### 2. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server (runs on http://localhost:5173)
npm run dev
```

### 3. Open in Browser

1. Navigate to `http://localhost:5173/`
2. Create a pet profile with name, age, size, activity level, and dietary goals
3. Add allergies by typing and pressing Enter
4. Click "Show Food Recommendation" to see personalized results!

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 18** - Modern UI library with hooks
- **Vite** - Lightning-fast build tool with HMR
- **React Router DOM** - Client-side routing
- **Axios** - HTTP client for API calls
- **CSS3** - Custom styles with gradients and animations

### Backend
- **Python 3.11** - Modern Python runtime
- **FastAPI** - High-performance async web framework
- **Motor** - Async MongoDB driver
- **Pydantic** - Data validation
- **python-dotenv** - Environment variable management
- **BeautifulSoup4 + lxml** - Web scraping for product data
- **Requests** - HTTP library for scraper

### Database
- **MongoDB** - NoSQL database (`petai`) for products and pet profiles

---

## ğŸ“¡ API Endpoints

### Pets
- `POST /api/pets` - Create a new pet profile
- `GET /api/pets/{pet_id}` - Get pet by ID

### Recommendations
- `GET /api/recommendations/{pet_id}` - Get personalized food recommendations
  - Returns top 15 products scored above 50 points
  - Applies hard filters (allergies, kibble size, life stage)
  - Sorted by compatibility score

### Products
- `GET /api/products` - List all products (admin)
- `GET /api/products/{product_id}` - Get product by ID

---

## ğŸ§ª Development

### Frontend Development
```bash
cd frontend
npm run dev     # Start dev server
npm run build   # Build for production
npm run preview # Preview production build
```

### Backend Development
```bash
cd backend
uvicorn main:app --reload --port 8000  # Start with auto-reload
python import_products.py              # Import sample data
python test_scraper.py                 # Test scraper functionality
```

### Web Scraping
```bash
cd backend
# Run Orijen scraper
python -c "from scrapers.orijen_scraper import OrijenScraper; scraper = OrijenScraper(); scraper.scrape_all_products()"
```

### Database Management
```bash
# Connect to MongoDB
mongosh

# Use database
use petai

# Query products
db.products.find()

# Query pets
db.pets.find()
```

---

## ğŸ“œ License

This project is not open source. All rights reserved Â© 2025 Mahyar JBR. Please do not copy, reuse, or distribute this code without permission.
